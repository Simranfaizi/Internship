{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddfa085c",
   "metadata": {},
   "source": [
    "## Web Scrapping Assignment 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f323bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementNotInteractableException "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98aab2d",
   "metadata": {},
   "source": [
    "### Q1- Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17ec0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dbe762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24a7aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making empty list\n",
    "rank=[]\n",
    "name=[]\n",
    "artist=[]\n",
    "upload_date=[]\n",
    "views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bdd3209",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:#getting rank \n",
    "    details=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div[3]/main/div[2]/div[3]/div[1]/table[2]/tbody/tr/td[1]')\n",
    "    for i in details:\n",
    "        rank.append(i.text)\n",
    "except:\n",
    "    rank.append('error')\n",
    "try:#getting name \n",
    "    details=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div[3]/main/div[2]/div[3]/div[1]/table[2]/tbody/tr/td[2]')\n",
    "    for i in details:\n",
    "        name.append(i.text.split(\"[\")[0])\n",
    "except:\n",
    "    name.append('error')\n",
    "try:#getting artist \n",
    "    details=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div[3]/main/div[2]/div[3]/div[1]/table[2]/tbody/tr/td[3]')\n",
    "    for i in details:\n",
    "        artist.append(i.text.split(\"[\")[0])\n",
    "except:\n",
    "    artist.append('error')\n",
    "\n",
    "#getting views\n",
    "try:# \n",
    "    details=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div[3]/main/div[2]/div[3]/div[1]/table[2]/tbody/tr/td[4]')\n",
    "    for i in details:\n",
    "        views.append(i.text.split(\"[\")[0])\n",
    "except:\n",
    "    views.append('error')\n",
    "\n",
    "#getting upload dates\n",
    "try:# \n",
    "    details=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div[3]/main/div[2]/div[3]/div[1]/table[2]/tbody/tr/td[5]')\n",
    "    for i in details:\n",
    "        upload_date.append(i.text.split(\"[\")[0])\n",
    "except:\n",
    "    upload_date.append('error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b33aaa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank length: 30\n",
      "Name length: 30\n",
      "Artist name Length: 30\n",
      "Views length: 30\n",
      "Length of uploading date: 30\n"
     ]
    }
   ],
   "source": [
    "print(\"Rank length:\",len(rank))\n",
    "print(\"Name length:\",len(name))\n",
    "print(\"Artist name Length:\",len(artist))\n",
    "print(\"Views length:\",len(views))\n",
    "print(\"Length of uploading date:\",len(upload_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "609a938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe\n",
    "video_df=pd.DataFrame({})\n",
    "video_df['Rank']=rank\n",
    "video_df['Name of the Video']=name\n",
    "video_df['Artist Name']=artist\n",
    "video_df['Views in Billions']=views\n",
    "video_df['uploaded Date']=upload_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d255ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_df.to_csv('famous_youtubev_ideos.csv') #saving into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "891946cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name of the Video</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Views in Billions</th>\n",
       "      <th>uploaded Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>12.13</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.07</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.59</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>5.96</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.89</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.76</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>5.12</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.84</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.80</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.79</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.66</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.52</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.21</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.81</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.72</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.71</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Axel F\"</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3.71</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.62</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Thinking Out Loud\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.54</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.48</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.44</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.43</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Faded\"</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.39</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.37</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Girls Like You\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.36</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.35</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Bailando\"</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.32</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Lean On\"</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.32</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.29</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.26</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                            Name of the Video  \\\n",
       "0    1.                           \"Baby Shark Dance\"   \n",
       "1    2.                                  \"Despacito\"   \n",
       "2    3.                       \"Johny Johny Yes Papa\"   \n",
       "3    4.                                  \"Bath Song\"   \n",
       "4    5.                               \"Shape of You\"   \n",
       "5    6.                              \"See You Again\"   \n",
       "6    7.                \"Phonics Song with Two Words\"   \n",
       "7    8.                          \"Wheels on the Bus\"   \n",
       "8    9.                                \"Uptown Funk\"   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"   \n",
       "10  11.                              \"Gangnam Style\"   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"   \n",
       "12  13.                             \"Dame Tu Cosita\"   \n",
       "13  14.                                      \"Sugar\"   \n",
       "14  15.                                       \"Roar\"   \n",
       "15  16.                             \"Counting Stars\"   \n",
       "16  17.                                     \"Axel F\"   \n",
       "17  18.                                      \"Sorry\"   \n",
       "18  19.                          \"Thinking Out Loud\"   \n",
       "19  20.                        \"Baa Baa Black Sheep\"   \n",
       "20  21.           \"Waka Waka (This Time for Africa)\"   \n",
       "21  22.                                 \"Dark Horse\"   \n",
       "22  23.                                      \"Faded\"   \n",
       "23  24.                                 \"Let Her Go\"   \n",
       "24  25.                             \"Girls Like You\"   \n",
       "25  26.                                    \"Perfect\"   \n",
       "26  27.                                   \"Bailando\"   \n",
       "27  28.                                    \"Lean On\"   \n",
       "28  29.          \"Humpty the train on a fruits ride\"   \n",
       "29  30.                             \"Lakdi Ki Kathi\"   \n",
       "\n",
       "                                      Artist Name Views in Billions  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories             12.13   \n",
       "1                                      Luis Fonsi              8.07   \n",
       "2                                     LooLoo Kids              6.59   \n",
       "3                      Cocomelon – Nursery Rhymes              5.96   \n",
       "4                                      Ed Sheeran              5.89   \n",
       "5                                     Wiz Khalifa              5.76   \n",
       "6                                       ChuChu TV              5.12   \n",
       "7                      Cocomelon – Nursery Rhymes              4.84   \n",
       "8                                     Mark Ronson              4.80   \n",
       "9                                     Miroshka TV              4.79   \n",
       "10                                            Psy              4.66   \n",
       "11                                     Get Movies              4.52   \n",
       "12                                      El Chombo              4.21   \n",
       "13                                       Maroon 5              3.81   \n",
       "14                                     Katy Perry              3.72   \n",
       "15                                    OneRepublic              3.71   \n",
       "16                                     Crazy Frog              3.71   \n",
       "17                                  Justin Bieber              3.62   \n",
       "18                                     Ed Sheeran              3.54   \n",
       "19                     Cocomelon – Nursery Rhymes              3.48   \n",
       "20                                        Shakira              3.44   \n",
       "21                                     Katy Perry              3.43   \n",
       "22                                    Alan Walker              3.39   \n",
       "23                                      Passenger              3.37   \n",
       "24                                       Maroon 5              3.36   \n",
       "25                                     Ed Sheeran              3.35   \n",
       "26                               Enrique Iglesias              3.32   \n",
       "27                                    Major Lazer              3.32   \n",
       "28  Kiddiestv Hindi – Nursery Rhymes & Kids Songs              3.29   \n",
       "29                                   Jingle Toons              3.26   \n",
       "\n",
       "        uploaded Date  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3         May 2, 2018  \n",
       "4    January 30, 2017  \n",
       "5       April 6, 2015  \n",
       "6       March 6, 2014  \n",
       "7        May 24, 2018  \n",
       "8   November 19, 2014  \n",
       "9   February 27, 2018  \n",
       "10      July 15, 2012  \n",
       "11   January 31, 2012  \n",
       "12      April 5, 2018  \n",
       "13   January 14, 2015  \n",
       "14  September 5, 2013  \n",
       "15       May 31, 2013  \n",
       "16      June 16, 2009  \n",
       "17   October 22, 2015  \n",
       "18    October 7, 2014  \n",
       "19      June 25, 2018  \n",
       "20       June 4, 2010  \n",
       "21  February 20, 2014  \n",
       "22   December 3, 2015  \n",
       "23      July 25, 2012  \n",
       "24       May 31, 2018  \n",
       "25   November 9, 2017  \n",
       "26     April 11, 2014  \n",
       "27     March 22, 2015  \n",
       "28   January 26, 2018  \n",
       "29      June 14, 2018  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed4f06ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b2c65b",
   "metadata": {},
   "source": [
    "### Q2-Scrape the details team India’s internationalfixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1stODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a32a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26df7b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.bcci.tv/')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03a18705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#landing on international fixture page\n",
    "international=driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a')\n",
    "international.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0734ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[] #making empty lists\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "time_data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3bf8db59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on more fixture button to get more data\n",
    "fixture_button=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div[2]/div/button')\n",
    "fixture_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27aa324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for title\n",
    "try:\n",
    "    title_tag=driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "    for i in title_tag:\n",
    "        title.append(i.text.split('-')[0])\n",
    "except:\n",
    "    title.append(\"-\")\n",
    "\n",
    "try:#for series\n",
    "\n",
    "    series_tag=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]')\n",
    "    for i in series_tag:\n",
    "        series.append(i.text)\n",
    "except:\n",
    "    series.append(\"-\")\n",
    "\n",
    "#for place\n",
    "\n",
    "try:\n",
    "    place_tag=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]')\n",
    "    for i in place_tag:\n",
    "        place.append(i.text)\n",
    "except:\n",
    "    place.append(\"-\")\n",
    "\n",
    "#for date\n",
    "\n",
    "try:\n",
    "    date_tag=driver.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]')\n",
    "    for i in date_tag:\n",
    "        date.append(i.text.split('-')[0])\n",
    "except:\n",
    "    date.append(\"-\")\n",
    "\n",
    "    \n",
    "#for time\n",
    "try:\n",
    "    time_tag=driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]')\n",
    "    for i in time_tag:\n",
    "        time_data.append(i.text.split('-')[0])\n",
    "except:\n",
    "    time_data.append(\"-\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aeb56c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 13 13 13 13\n"
     ]
    }
   ],
   "source": [
    "print(len(title),len(series),len(place),len(date),len(time_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "522155fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe\n",
    "bcci_df=pd.DataFrame({'Title':title,\n",
    "                     'Match Series':series,\n",
    "                     'Place':place,\n",
    "                     'Date':date,\n",
    "                     'Time':time_data})\n",
    "\n",
    "\n",
    "bcci_df.to_csv('bcci.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "91986e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Match Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>NEW ZEALAND TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Narendra Modi Stadium,</td>\n",
       "      <td>1 FEB 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5th T20I</td>\n",
       "      <td>WOMENS T20I TRI</td>\n",
       "      <td>Buffalo Park,</td>\n",
       "      <td>2 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022</td>\n",
       "      <td>Vidarbha Cricket Association Stadium,</td>\n",
       "      <td>9 FEB 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>Newlands,</td>\n",
       "      <td>12 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>Newlands,</td>\n",
       "      <td>15 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022</td>\n",
       "      <td>Arun Jaitley Stadium,</td>\n",
       "      <td>17 FEB 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>St George's Park,</td>\n",
       "      <td>18 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4th T20I</td>\n",
       "      <td>ICC WOMENS T20 WORLD CUP 2023</td>\n",
       "      <td>St George's Park,</td>\n",
       "      <td>20 FEB 2023</td>\n",
       "      <td>6:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium,</td>\n",
       "      <td>1 MAR 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA TEST SERIES 2022</td>\n",
       "      <td>Narendra Modi Stadium,</td>\n",
       "      <td>9 MAR 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA ODI SERIES 2022</td>\n",
       "      <td>Wankhede Stadium,</td>\n",
       "      <td>17 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA ODI SERIES 2022</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA</td>\n",
       "      <td>19 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>AUSTRALIA TOUR OF INDIA ODI SERIES 2022</td>\n",
       "      <td>MA Chidambaram Stadium,</td>\n",
       "      <td>22 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Title                               Match Series  \\\n",
       "0   3rd T20I   NEW ZEALAND TOUR OF INDIA T20 SERIES 2022   \n",
       "1   5th T20I                             WOMENS T20I TRI   \n",
       "2   1st Test    AUSTRALIA TOUR OF INDIA TEST SERIES 2022   \n",
       "3   1st T20I               ICC WOMENS T20 WORLD CUP 2023   \n",
       "4   2nd T20I               ICC WOMENS T20 WORLD CUP 2023   \n",
       "5   2nd Test    AUSTRALIA TOUR OF INDIA TEST SERIES 2022   \n",
       "6   3rd T20I               ICC WOMENS T20 WORLD CUP 2023   \n",
       "7   4th T20I               ICC WOMENS T20 WORLD CUP 2023   \n",
       "8   3rd Test    AUSTRALIA TOUR OF INDIA TEST SERIES 2022   \n",
       "9   4th Test    AUSTRALIA TOUR OF INDIA TEST SERIES 2022   \n",
       "10   1st ODI     AUSTRALIA TOUR OF INDIA ODI SERIES 2022   \n",
       "11   2nd ODI     AUSTRALIA TOUR OF INDIA ODI SERIES 2022   \n",
       "12   3rd ODI     AUSTRALIA TOUR OF INDIA ODI SERIES 2022   \n",
       "\n",
       "                                            Place         Date         Time  \n",
       "0                          Narendra Modi Stadium,   1 FEB 2023  7:00 PM IST  \n",
       "1                                   Buffalo Park,   2 FEB 2023  6:30 PM IST  \n",
       "2           Vidarbha Cricket Association Stadium,   9 FEB 2023  9:30 AM IST  \n",
       "3                                       Newlands,  12 FEB 2023  6:30 PM IST  \n",
       "4                                       Newlands,  15 FEB 2023  6:30 PM IST  \n",
       "5                           Arun Jaitley Stadium,  17 FEB 2023  9:30 AM IST  \n",
       "6                               St George's Park,  18 FEB 2023  6:30 PM IST  \n",
       "7                               St George's Park,  20 FEB 2023  6:30 PM IST  \n",
       "8   Himachal Pradesh Cricket Association Stadium,   1 MAR 2023  9:30 AM IST  \n",
       "9                          Narendra Modi Stadium,   9 MAR 2023  9:30 AM IST  \n",
       "10                              Wankhede Stadium,  17 MAR 2023  1:30 PM IST  \n",
       "11                    Dr YS Rajasekhara Reddy ACA  19 MAR 2023  1:30 PM IST  \n",
       "12                        MA Chidambaram Stadium,  22 MAR 2023  1:30 PM IST  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcci_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "de6e1b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46a1f43",
   "metadata": {},
   "source": [
    "### Q3-Scrape the details of State-wise GDP ofIndia fromstatisticstime.com. \n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3c57a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1f9ab501",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://statisticstimes.com/')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "060716d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#landing on economy page\n",
    "try:\n",
    "    economy=driver.find_element(By.XPATH,'//div[@class=\"navbar\"]/div[2]/div/a[3]')\n",
    "    link=economy.get_attribute('href')\n",
    "    driver.get(link)\n",
    "\n",
    "except:\n",
    "    print(\"not intrcatable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "54b8db5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #clicking on gdp of indian states\n",
    "    gdp=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "    gdp_link=gdp.get_attribute('href')\n",
    "    driver.get(gdp_link)\n",
    "    time.sleep(5)\n",
    "except:\n",
    "    print('not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "af3d3205",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "state=[]\n",
    "gsdp_1819=[]\n",
    "gsdp_1920=[]\n",
    "share=[]\n",
    "gdp=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "57237cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for rank\n",
    "try:\n",
    "    ranks=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "    for i in ranks:\n",
    "        rank.append(i.text)\n",
    "except:\n",
    "    rank.append(\"-\")\n",
    "\n",
    "#for state \n",
    "try:\n",
    "    states=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "    for i in states:\n",
    "        state.append(i.text)\n",
    "except:\n",
    "    state.append(\"-\")\n",
    "\n",
    "#for gsdp-1819\n",
    "try:\n",
    "    gdsp_tag1=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "    for i in gdsp_tag1:\n",
    "        gsdp_1819.append(i.text)\n",
    "except:\n",
    "    gsdp_1819.append(\"-\")\n",
    "#gdsp_1819.insert(32,\"-\")\n",
    "\n",
    "#for gdsp-1920\n",
    "try:\n",
    "    gdsp_tag2=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[3]')\n",
    "    for i in gdsp_tag2:\n",
    "        gsdp_1920.append(i.text)\n",
    "except:\n",
    "    gsdp_1920.append(\"-\")\n",
    "\n",
    "\n",
    "try: #for share\n",
    "    share_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "    for i in share_tag:\n",
    "        share.append(i.text)\n",
    "except:\n",
    "    share.append(\"-\")\n",
    "    \n",
    "#for gdp\n",
    "try: \n",
    "    gdp_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "    for i in gdp_tag:\n",
    "        gdp.append(i.text)\n",
    "except:\n",
    "    gdp.append(\"-\")    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3a5a0fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 33 33 33 33 33\n"
     ]
    }
   ],
   "source": [
    "print(len(rank),len(state),len(gsdp_1920),len(gsdp_1819),len(share),len(gdp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5a296cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_state=pd.DataFrame({'Rank':rank,\n",
    "                       'State':state,\n",
    "                       'GSDP-1819':gsdp_1819,\n",
    "                       'GSDP-1920':gsdp_1920,\n",
    "                       'Share(18-19)':share,\n",
    "                       'GDP($billion)':gdp})\n",
    "gdp_state.to_csv('gdpstate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1194077d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP-1819</th>\n",
       "      <th>GSDP-1920</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State  GSDP-1819  GSDP-1920 Share(18-19)  \\\n",
       "0     1                Maharashtra  2,632,792          -       13.94%   \n",
       "1     2                 Tamil Nadu  1,630,208  1,845,853        8.63%   \n",
       "2     3              Uttar Pradesh  1,584,764  1,687,818        8.39%   \n",
       "3     4                    Gujarat  1,502,899          -        7.96%   \n",
       "4     5                  Karnataka  1,493,127  1,631,977        7.91%   \n",
       "5     6                West Bengal  1,089,898  1,253,832        5.77%   \n",
       "6     7                  Rajasthan    942,586  1,020,989        4.99%   \n",
       "7     8             Andhra Pradesh    862,957    972,782        4.57%   \n",
       "8     9                  Telangana    861,031    969,604        4.56%   \n",
       "9    10             Madhya Pradesh    809,592    906,672        4.29%   \n",
       "10   11                     Kerala    781,653          -        4.14%   \n",
       "11   12                      Delhi    774,870    856,112        4.10%   \n",
       "12   13                    Haryana    734,163    831,610        3.89%   \n",
       "13   14                      Bihar    530,363    611,804        2.81%   \n",
       "14   15                     Punjab    526,376    574,760        2.79%   \n",
       "15   16                     Odisha    487,805    521,275        2.58%   \n",
       "16   17                      Assam    315,881          -        1.67%   \n",
       "17   18               Chhattisgarh    304,063    329,180        1.61%   \n",
       "18   19                  Jharkhand    297,204    328,598        1.57%   \n",
       "19   20                Uttarakhand    245,895          -        1.30%   \n",
       "20   21            Jammu & Kashmir    155,956          -        0.83%   \n",
       "21   22           Himachal Pradesh    153,845    165,472        0.81%   \n",
       "22   23                        Goa     73,170     80,449        0.39%   \n",
       "23   24                    Tripura     49,845     55,984        0.26%   \n",
       "24   25                 Chandigarh     42,114          -        0.22%   \n",
       "25   26                 Puducherry     34,433     38,253        0.18%   \n",
       "26   27                  Meghalaya     33,481     36,572        0.18%   \n",
       "27   28                     Sikkim     28,723     32,496        0.15%   \n",
       "28   29                    Manipur     27,870     31,790        0.15%   \n",
       "29   30                   Nagaland     27,283          -        0.14%   \n",
       "30   31          Arunachal Pradesh     24,603          -        0.13%   \n",
       "31   32                    Mizoram     22,287     26,503        0.12%   \n",
       "32   33  Andaman & Nicobar Islands          -          -            -   \n",
       "\n",
       "   GDP($billion)  \n",
       "0        399.921  \n",
       "1        247.629  \n",
       "2        240.726  \n",
       "3        228.290  \n",
       "4        226.806  \n",
       "5        165.556  \n",
       "6        143.179  \n",
       "7        131.083  \n",
       "8        130.791  \n",
       "9        122.977  \n",
       "10       118.733  \n",
       "11       117.703  \n",
       "12       111.519  \n",
       "13        80.562  \n",
       "14        79.957  \n",
       "15        74.098  \n",
       "16        47.982  \n",
       "17        46.187  \n",
       "18        45.145  \n",
       "19        37.351  \n",
       "20        23.690  \n",
       "21        23.369  \n",
       "22        11.115  \n",
       "23         7.571  \n",
       "24         6.397  \n",
       "25         5.230  \n",
       "26         5.086  \n",
       "27         4.363  \n",
       "28         4.233  \n",
       "29         4.144  \n",
       "30         3.737  \n",
       "31         3.385  \n",
       "32             -  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "304ed9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea1bcd6",
   "metadata": {},
   "source": [
    "### Q4-Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f701945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14b4b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://github.com/')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8fd4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#landing on trending page b slecting opensource.\n",
    "open_source=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "open_source.click()\n",
    "\n",
    "trending=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a')\n",
    "link=trending.get_attribute('href')\n",
    "driver.get(link)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "46a18126",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository=[]\n",
    "repos_link=[]\n",
    "description=[]\n",
    "counts=[]\n",
    "language=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f08c27d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "073ea3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#.for repository name\n",
    "try:\n",
    "    name_tag=driver.find_elements(By.XPATH,'/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article/h1/a')\n",
    "    for i in name_tag:\n",
    "        repository.append(i.text)\n",
    "        \n",
    "except:\n",
    "    repository.append(\"-\")\n",
    "\n",
    "#for link of each repository\n",
    "try:\n",
    "    name_tag=driver.find_elements(By.XPATH,'/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article/h1/a')\n",
    "    for i in name_tag:\n",
    "        repos_link.append(i.get_attribute('href'))\n",
    "except NoSuchElementException:\n",
    "    repos_link.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e6b49d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in repos_link:\n",
    "    driver.get(link)\n",
    "    time.sleep(5)\n",
    "    try: #for description\n",
    "        descriptions=driver.find_element(By.XPATH,'//div[@class=\"BorderGrid-row hide-sm hide-md\"]/div[1]/p')\n",
    "        description.append(descriptions.text)\n",
    "    except NoSuchElementException:\n",
    "        description.append(\"-\")\n",
    "    \n",
    "    try: #for language\n",
    "        language_tags=driver.find_element(By.XPATH,'//li[@class=\"d-inline\"]/a/span')\n",
    "        language.append(language_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        language.append(\"-\")\n",
    "    \n",
    "    try: #contributers count\n",
    "        contributers=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/main/turbo-frame/div/div/div/div[3]/div[2]/div/div[5]/div/h2/a/span')\n",
    "        counts.append(contributers.text)\n",
    "    except NoSuchElementException:\n",
    "        counts.append(\"-\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d12c992c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository Name column length: 25\n",
      "Length of Repository Links: 25\n",
      "Description column length: 25\n",
      "Language column length: 25\n",
      "Contributers Count column length: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"Repository Name column length:\",len(repository))\n",
    "print(\"Length of Repository Links:\",len(repos_link))\n",
    "print(\"Description column length:\",len(description))\n",
    "print(\"Language column length:\",len(language))\n",
    "print(\"Contributers Count column length:\",len(counts))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c8d5518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe\n",
    "github_df=pd.DataFrame({'Repository':repository,\n",
    "                       'Description':description,\n",
    "                       'Contributorscount':counts,\n",
    "                       'Language':language})\n",
    "github_df.to_csv('github.csv') #saving into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2793699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository</th>\n",
       "      <th>Description</th>\n",
       "      <th>Contributorscount</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>snesrev / zelda3</td>\n",
       "      <td>-</td>\n",
       "      <td>19</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transitive-bullshit / chatgpt-api</td>\n",
       "      <td>Node.js client for the unofficial ChatGPT API. 🔥</td>\n",
       "      <td>5.5k</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microsoft / PowerToys</td>\n",
       "      <td>Windows system utilities to maximize productivity</td>\n",
       "      <td>-</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>microsoft / winget-cli</td>\n",
       "      <td>Windows Package Manager CLI (aka winget)</td>\n",
       "      <td>83</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bnb-chain / greenfield-whitepaper</td>\n",
       "      <td>Whitepaper for Greenfield, the decentralized d...</td>\n",
       "      <td>6</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>krahets / hello-algo</td>\n",
       "      <td>《Hello 算法》一本动画图解、能运行、可提问的数据结构与算法入门书，支持 Java, C...</td>\n",
       "      <td>-</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>damus-io / damus</td>\n",
       "      <td>iOS nostr client</td>\n",
       "      <td>44</td>\n",
       "      <td>Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>techiescamp / kubernetes-learning-path</td>\n",
       "      <td>A roadmap to learn Kubernetes from scratch (Be...</td>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>iperov / DeepFaceLive</td>\n",
       "      <td>Real-time face swap for PC streaming or video ...</td>\n",
       "      <td>7</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>microsoft / BioGPT</td>\n",
       "      <td>-</td>\n",
       "      <td>6</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>varunshenoy / GraphGPT</td>\n",
       "      <td>Extrapolating knowledge graphs from unstructur...</td>\n",
       "      <td>-</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>apitable / apitable</td>\n",
       "      <td>🚀🎉📚 APITable, an API-oriented low-code platfor...</td>\n",
       "      <td>-</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>golang / go</td>\n",
       "      <td>The Go programming language</td>\n",
       "      <td>1,923</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>karpathy / nanoGPT</td>\n",
       "      <td>The simplest, fastest repository for training/...</td>\n",
       "      <td>11</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wangrongding / wechat-bot</td>\n",
       "      <td>🤖一个基于OpenAi ChatGPT + WeChaty 实现的微信机器人 ，可以用来帮助...</td>\n",
       "      <td>5</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mtdvio / every-programmer-should-know</td>\n",
       "      <td>A collection of (mostly) technical things ever...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>studio-freight / lenis</td>\n",
       "      <td>How smooth scroll should be</td>\n",
       "      <td>-</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>archinetai / audio-ai-timeline</td>\n",
       "      <td>A timeline of the latest AI models for audio g...</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>triggerdotdev / trigger.dev</td>\n",
       "      <td>✨ Trigger.dev is an open-source platform that ...</td>\n",
       "      <td>-</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nostr-protocol / nostr</td>\n",
       "      <td>a truly censorship-resistant alternative to Tw...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>waylaidwanderer / node-chatgpt-api</td>\n",
       "      <td>A ChatGPT implementation using the official Ch...</td>\n",
       "      <td>4</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>acheong08 / ChatGPT</td>\n",
       "      <td>Reverse engineered ChatGPT API. Uses official ...</td>\n",
       "      <td>49</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dair-ai / Prompt-Engineering-Guide</td>\n",
       "      <td>🐙 Guide and resources for prompt engineering</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ossu / computer-science</td>\n",
       "      <td>🎓 Path to a free self-taught education in Comp...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GitHubDaily / GitHubDaily</td>\n",
       "      <td>坚持分享 GitHub 上高质量、有趣实用的开源技术教程、开发者工具、编程网站、技术资讯。A...</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Repository  \\\n",
       "0                         snesrev / zelda3   \n",
       "1        transitive-bullshit / chatgpt-api   \n",
       "2                    microsoft / PowerToys   \n",
       "3                   microsoft / winget-cli   \n",
       "4        bnb-chain / greenfield-whitepaper   \n",
       "5                     krahets / hello-algo   \n",
       "6                         damus-io / damus   \n",
       "7   techiescamp / kubernetes-learning-path   \n",
       "8                    iperov / DeepFaceLive   \n",
       "9                       microsoft / BioGPT   \n",
       "10                  varunshenoy / GraphGPT   \n",
       "11                     apitable / apitable   \n",
       "12                             golang / go   \n",
       "13                      karpathy / nanoGPT   \n",
       "14               wangrongding / wechat-bot   \n",
       "15   mtdvio / every-programmer-should-know   \n",
       "16                  studio-freight / lenis   \n",
       "17          archinetai / audio-ai-timeline   \n",
       "18             triggerdotdev / trigger.dev   \n",
       "19                  nostr-protocol / nostr   \n",
       "20      waylaidwanderer / node-chatgpt-api   \n",
       "21                     acheong08 / ChatGPT   \n",
       "22      dair-ai / Prompt-Engineering-Guide   \n",
       "23                 ossu / computer-science   \n",
       "24               GitHubDaily / GitHubDaily   \n",
       "\n",
       "                                          Description Contributorscount  \\\n",
       "0                                                   -                19   \n",
       "1    Node.js client for the unofficial ChatGPT API. 🔥              5.5k   \n",
       "2   Windows system utilities to maximize productivity                 -   \n",
       "3            Windows Package Manager CLI (aka winget)                83   \n",
       "4   Whitepaper for Greenfield, the decentralized d...                 6   \n",
       "5   《Hello 算法》一本动画图解、能运行、可提问的数据结构与算法入门书，支持 Java, C...                 -   \n",
       "6                                    iOS nostr client                44   \n",
       "7   A roadmap to learn Kubernetes from scratch (Be...                 4   \n",
       "8   Real-time face swap for PC streaming or video ...                 7   \n",
       "9                                                   -                 6   \n",
       "10  Extrapolating knowledge graphs from unstructur...                 -   \n",
       "11  🚀🎉📚 APITable, an API-oriented low-code platfor...                 -   \n",
       "12                        The Go programming language             1,923   \n",
       "13  The simplest, fastest repository for training/...                11   \n",
       "14  🤖一个基于OpenAi ChatGPT + WeChaty 实现的微信机器人 ，可以用来帮助...                 5   \n",
       "15  A collection of (mostly) technical things ever...                 -   \n",
       "16                        How smooth scroll should be                 -   \n",
       "17  A timeline of the latest AI models for audio g...                 3   \n",
       "18  ✨ Trigger.dev is an open-source platform that ...                 -   \n",
       "19  a truly censorship-resistant alternative to Tw...                 -   \n",
       "20  A ChatGPT implementation using the official Ch...                 4   \n",
       "21  Reverse engineered ChatGPT API. Uses official ...                49   \n",
       "22       🐙 Guide and resources for prompt engineering                 -   \n",
       "23  🎓 Path to a free self-taught education in Comp...                 -   \n",
       "24  坚持分享 GitHub 上高质量、有趣实用的开源技术教程、开发者工具、编程网站、技术资讯。A...                 3   \n",
       "\n",
       "            Language  \n",
       "0                  C  \n",
       "1         TypeScript  \n",
       "2                 C#  \n",
       "3                C++  \n",
       "4                  -  \n",
       "5               Java  \n",
       "6              Swift  \n",
       "7                  -  \n",
       "8             Python  \n",
       "9             Python  \n",
       "10        JavaScript  \n",
       "11        TypeScript  \n",
       "12                Go  \n",
       "13  Jupyter Notebook  \n",
       "14        JavaScript  \n",
       "15                 -  \n",
       "16        JavaScript  \n",
       "17                 -  \n",
       "18        TypeScript  \n",
       "19                 -  \n",
       "20        JavaScript  \n",
       "21            Python  \n",
       "22                 -  \n",
       "23                 -  \n",
       "24                 -  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4d311ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1095a3e6",
   "metadata": {},
   "source": [
    "### Q5- Scrape the details of top 100 songs on billiboard.com. \n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ab0bf33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "aaedf254",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.billboard.com/')\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5eed46b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#landing on charts page\n",
    "try:\n",
    "    chart_tag=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "    link=chart_tag.get_attribute('href')\n",
    "    driver.get(link)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    \n",
    "except:\n",
    "    print(\"Page not found or not clickable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "81aaf7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    top_chart=driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div/div[2]/span/a')\n",
    "    top_link=top_chart.get_attribute('href')\n",
    "    driver.get(top_link)\n",
    "    time.sleep(5)\n",
    "    \n",
    "except:\n",
    "    print(\"not valid xpath\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8b3246df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty list\n",
    "song=[]\n",
    "artist=[]\n",
    "lw_rank=[]\n",
    "peak_rank=[]\n",
    "wob=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "df71f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#song name scrapping\n",
    "try:\n",
    "    song_tag=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li/h3')\n",
    "    for i in song_tag:\n",
    "        song.append(i.text)\n",
    "except:\n",
    "    song.append(\"-\")\n",
    "    \n",
    "try: #for artist\n",
    "    arts_tag=driver.find_elements(By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]/li[1]')\n",
    "    for i in arts_tag:\n",
    "        artist.append(i.text.split(\"\\n\")[1])\n",
    "        #song.append(i.text)\n",
    "except:\n",
    "    artist.append(\"-\")\n",
    "    \n",
    "try: #for lastweek rank\n",
    "    rank_tag=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[4]/span')\n",
    "    for i in rank_tag:\n",
    "        lw_rank.append(i.text)\n",
    "except:\n",
    "     lw_rank.append(\"-\")\n",
    "\n",
    "try: #for peak rank\n",
    "    pkrank_tag=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[5]/span')\n",
    "    for i in pkrank_tag:\n",
    "        peak_rank.append(i.text)\n",
    "        \n",
    "except:\n",
    "    peak_rank.append(\"-\")\n",
    "\n",
    "try: #for peak rank\n",
    "    wob_tag=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]/ul/li[6]')\n",
    "    for i in wob_tag:\n",
    "        wob.append(i.text)\n",
    "        \n",
    "except:\n",
    "    wob.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "39e91e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(song),len(artist),len(peak_rank),len(lw_rank),len(wob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9d95901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe\n",
    "billboard_df=pd.DataFrame({'Song':song,\n",
    "                          'Artist':artist,\n",
    "                          'Lastweek Rank':lw_rank,\n",
    "                          'Peak Rank':peak_rank,\n",
    "                          'Weeks on Board':wob})\n",
    "billboard_df.to_csv('Billborad 100.csv')#saving into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7629b040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Lastweek Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>SZA</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anti-Hero</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creepin'</td>\n",
       "      <td>Metro Boomin, The Weeknd &amp; 21 Savage</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unholy</td>\n",
       "      <td>Sam Smith &amp; Kim Petras</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Do It Again</td>\n",
       "      <td>NLE Choppa &amp; 2Rare</td>\n",
       "      <td>-</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Miss You</td>\n",
       "      <td>Oliver Tree &amp; Robin Schulz</td>\n",
       "      <td>96</td>\n",
       "      <td>84</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Back End</td>\n",
       "      <td>Finesse2Tymes</td>\n",
       "      <td>-</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Open Arms</td>\n",
       "      <td>SZA Featuring Travis Scott</td>\n",
       "      <td>89</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Spit In My Face!</td>\n",
       "      <td>ThxSoMch</td>\n",
       "      <td>-</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Song                                Artist Lastweek Rank  \\\n",
       "0            Flowers                           Miley Cyrus             1   \n",
       "1          Kill Bill                                   SZA             2   \n",
       "2          Anti-Hero                          Taylor Swift             3   \n",
       "3           Creepin'  Metro Boomin, The Weeknd & 21 Savage             4   \n",
       "4             Unholy                Sam Smith & Kim Petras             5   \n",
       "..               ...                                   ...           ...   \n",
       "95       Do It Again                    NLE Choppa & 2Rare             -   \n",
       "96          Miss You            Oliver Tree & Robin Schulz            96   \n",
       "97          Back End                         Finesse2Tymes             -   \n",
       "98         Open Arms            SZA Featuring Travis Scott            89   \n",
       "99  Spit In My Face!                              ThxSoMch             -   \n",
       "\n",
       "   Peak Rank Weeks on Board  \n",
       "0          1              2  \n",
       "1          2              7  \n",
       "2          1             14  \n",
       "3          4              8  \n",
       "4          1             18  \n",
       "..       ...            ...  \n",
       "95        96              1  \n",
       "96        84              9  \n",
       "97        98              1  \n",
       "98        54              6  \n",
       "99       100              1  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billboard_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "91d1e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b39d96",
   "metadata": {},
   "source": [
    "### Q6-Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n",
    "\n",
    "\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f7f32ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')\n",
    "driver.maximize_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c06b9680",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17e72130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making empty list\n",
    "name=[]\n",
    "authors=[]\n",
    "volume_sold=[]\n",
    "publisher=[]\n",
    "genre=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3dbadbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Name column 100\n",
      "Length of Authors column 100\n",
      "Length of Volume sold column 100\n",
      "length of Publiser column 100\n",
      "length of Genre column 100\n"
     ]
    }
   ],
   "source": [
    "#for name\n",
    "try:\n",
    "    name_tag=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[2]')\n",
    "    for i in name_tag:\n",
    "        name.append(i.text)\n",
    "        \n",
    "except:\n",
    "     name.append(\"-\")\n",
    "#for authors\n",
    "try:\n",
    "    authors_tag=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[3]')\n",
    "    for i in authors_tag:\n",
    "        authors.append(i.text)\n",
    "        \n",
    "except:\n",
    "     authors.append(\"-\")\n",
    "#for volume sold\n",
    "try:\n",
    "    sales_tag=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[4]')\n",
    "    for i in sales_tag:\n",
    "        volume_sold.append(i.text)\n",
    "        \n",
    "except:\n",
    "     volume_sold.append(\"-\")\n",
    "\n",
    "# for publisher\n",
    "\n",
    "try:\n",
    "    publisher_tag=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[5]')\n",
    "    for i in publisher_tag:\n",
    "        publisher.append(i.text)\n",
    "        \n",
    "except:\n",
    "     publisher.append(\"-\")\n",
    "\n",
    "#for genre\n",
    "try:\n",
    "    genre_tag=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[6]')\n",
    "    for i in genre_tag:\n",
    "        genre.append(i.text)\n",
    "        \n",
    "except:\n",
    "     genre.append(\"-\")        \n",
    "        \n",
    "print(\"Length of Name column\",len(name))\n",
    "print(\"Length of Authors column\",len(authors))\n",
    "print(\"Length of Volume sold column\",len(volume_sold))\n",
    "print(\"length of Publiser column\",len(publisher))\n",
    "print(\"length of Genre column\",len(genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e8568f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe\n",
    "novels_df=pd.DataFrame({'Novel Name':name,\n",
    "                       'Author':authors,\n",
    "                       'Volume Sold':volume_sold,\n",
    "                       'Publsher':publisher,\n",
    "                       'Genre':genre})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5380bac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Novel Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume Sold</th>\n",
       "      <th>Publsher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Novel Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume Sold         Publsher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novels_df.to_csv('Novels.csv') #saving into csv file\n",
    "novels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7995513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ac1627",
   "metadata": {},
   "source": [
    "### Q7- Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "\n",
    "\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7178562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33ab4bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.imdb.com/list/ls095964455/')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6d26c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list creation\n",
    "name=[]\n",
    "span_year=[]\n",
    "genres=[]\n",
    "run_time=[]\n",
    "rating=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b865309e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name column length: 100\n",
      "Span Year column length : 100\n",
      "Genres column length : 100\n",
      "Runtime column length : 100\n",
      "Rating column length: 100\n"
     ]
    }
   ],
   "source": [
    "#getting name details \n",
    "try:\n",
    "    name_tag=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')\n",
    "    for i in name_tag:\n",
    "        name.append(i.text)\n",
    "        \n",
    "except:\n",
    "     name.append(\"-\")\n",
    "        \n",
    "#span year\n",
    "try:\n",
    "    year_tag=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/span[2]')\n",
    "    for i in year_tag:\n",
    "        span_year.append(i.text)\n",
    "        \n",
    "except:\n",
    "     span_year.append(\"-\")\n",
    "\n",
    "#genres \n",
    "try:\n",
    "    genre_tag=driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')\n",
    "    for i in genre_tag:\n",
    "        genres.append(i.text)\n",
    "        \n",
    "except:\n",
    "     genres.append(\"-\")\n",
    "\n",
    "#for run time\n",
    "try:\n",
    "    time_tag=driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')\n",
    "    for i in time_tag:\n",
    "        run_time.append(i.text)\n",
    "        \n",
    "except:\n",
    "     run_time.append(\"-\")        \n",
    "\n",
    "#rating\n",
    "try:\n",
    "    rating_tag=driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]/span[2]')\n",
    "    for i in rating_tag:\n",
    "        rating.append(i.text)\n",
    "        \n",
    "except:\n",
    "    rating.append(\"-\") \n",
    "print(\"Name column length:\",len(name))\n",
    "print(\"Span Year column length :\",len(span_year))\n",
    "print(\"Genres column length :\",len( genres))\n",
    "print(\"Runtime column length :\",len(run_time))\n",
    "print(\"Rating column length:\",len(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd732395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making dataframe\n",
    "tv_serial=pd.DataFrame({'Name':name,\n",
    "                       'Span Year':span_year,\n",
    "                       'Genre':genres,\n",
    "                       'Runtime':run_time,\n",
    "                       'Rating':rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b936e820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Span Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Drama</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Span Year                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "                     Runtime Rating  \n",
       "0   Action, Adventure, Drama    9.2  \n",
       "1     Drama, Fantasy, Horror    8.7  \n",
       "2    Drama, Horror, Thriller    8.1  \n",
       "3   Drama, Mystery, Thriller    7.5  \n",
       "4     Drama, Mystery, Sci-Fi    7.6  \n",
       "..                       ...    ...  \n",
       "95                     Drama    7.4  \n",
       "96  Adventure, Comedy, Drama    7.8  \n",
       "97     Crime, Drama, Mystery    8.1  \n",
       "98      Comedy, Crime, Drama    7.1  \n",
       "99    Drama, Horror, Mystery    8.6  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_serial.to_csv('tvserial.csv')\n",
    "tv_serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cff7c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b2d666",
   "metadata": {},
   "source": [
    "### Q8-Details of Datasets from UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9e031bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'chromedriver.exe')\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "da6332df",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://archive.ics.uci.edu/ml/index.php')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f910db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#landing on view all dataset page\n",
    "page=driver.find_element(By.XPATH,'/html/body/table[1]/tbody/tr/td[2]/span[2]/a')\n",
    "link=page.get_attribute('href')\n",
    "driver.get(link)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5f227b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsname=[]\n",
    "dtype=[]\n",
    "task=[]\n",
    "attributes=[]\n",
    "instances=[]\n",
    "no_of_attribute=[]\n",
    "year=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9290a8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of Dataset name columns: 623\n",
      "length of Dataset type columns: 623\n",
      "length of Task columns: 623\n",
      "length of Attributes columns: 623\n",
      "length of Insatnce columns: 623\n",
      "length of No of Attribtutes columns: 623\n",
      "length of Year columns: 623\n"
     ]
    }
   ],
   "source": [
    "try:#for dataset name\n",
    "    ds=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[1]')\n",
    "    for i in ds:\n",
    "        dsname.append(i.text.split(\"\\n\")[0])\n",
    "        \n",
    "except:\n",
    "    dsname.append(\"-\")\n",
    "\n",
    "try:#for dataset type\n",
    "    ds=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]')\n",
    "    for i in ds:\n",
    "        dtype.append(i.text)\n",
    "        \n",
    "except:\n",
    "    dtype.append(\"-\")    \n",
    "\n",
    "try:#for task\n",
    "    ds=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]')\n",
    "    for i in ds:\n",
    "        task.append(i.text)       \n",
    "        \n",
    "except:\n",
    "    task.append(\"-\")   \n",
    "    \n",
    "try:#for attributes\n",
    "    attri_tag=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]')\n",
    "    for i in attri_tag:\n",
    "        attributes.append(i.text)\n",
    "except:\n",
    "    attributes.append(\"-\")   \n",
    "\n",
    "\n",
    "#for instances\n",
    "\n",
    "try:\n",
    "    instances_tag=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]')\n",
    "    for i in instances_tag:\n",
    "        instances.append(i.text)\n",
    "except:\n",
    "    instances.append(\"-\")  \n",
    "    \n",
    "try:#for no_of_attribute\n",
    "    attributes=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]')\n",
    "    for i in attributes:\n",
    "        no_of_attribute.append(i.text)       \n",
    "        \n",
    "except:\n",
    "    no_of_attribute.append(\"-\")     \n",
    "    \n",
    "try:#for year\n",
    "    yeartag=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]')\n",
    "    for i in yeartag:\n",
    "        year.append(i.text)       \n",
    "        \n",
    "except:\n",
    "    year.append(\"-\")    \n",
    "\n",
    "print(\"length of Dataset name columns:\",len(dsname))\n",
    "print(\"length of Dataset type columns:\",len(dtype))\n",
    "print(\"length of Task columns:\",len(task))\n",
    "print(\"length of Attributes columns:\",len(attributes))\n",
    "print(\"length of Insatnce columns:\",len(instances))\n",
    "print(\"length of No of Attribtutes columns:\",len(no_of_attribute))\n",
    "print(\"length of Year columns:\",len(year))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fa3557a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataframe\n",
    "datasaet_df=pd.DataFrame({'Dataset Name':dsname[1:],'DataType':dtype[1:],\n",
    "                         'Deafult Task':task[1:],'Attribute Types':attributes[1:],\n",
    "                         'No of Instances':instances[1:],'No of Attributes':no_of_attribute[1:],\n",
    "                         'Year':year[1:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "373a8acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>DataType</th>\n",
       "      <th>Deafult Task</th>\n",
       "      <th>Attribute Types</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>No of Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twit...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mo...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset Name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617    Influenza outbreak event prediction via Twit...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621    Image Recognition Task Execution Times in Mo...   \n",
       "\n",
       "                       DataType          Deafult Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                 Attribute Types No of Instances No of Attributes   Year  \n",
       "0    Categorical, Integer, Real            4177                8   1995   \n",
       "1          Categorical, Integer           48842               14   1996   \n",
       "2    Categorical, Integer, Real             798               38          \n",
       "3                   Categorical           37711              294   1998   \n",
       "4    Categorical, Integer, Real             452              279   1998   \n",
       "..                           ...             ...              ...    ...  \n",
       "617               Integer, Real           75840              525   2020   \n",
       "618               Integer, Real             400               50   2020   \n",
       "619                                        1014                7   2020   \n",
       "620                        Real           10129               16   2021   \n",
       "621                        Real            4000                2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasaet_df.to_csv('datasetrepository.csv')\n",
    "datasaet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9a9c1317",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10a7db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69c502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
